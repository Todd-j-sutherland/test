# üèÜ ML Trading System - Complete User Guide

*The only guide you need for your ML-enhanced ASX banking trading system*

---

## üöÄ **SYSTEM OVERVIEW**

### **What This System Does**
- **ü§ñ ML-Enhanced Trading** - Analyzes news sentiment and predicts profitable trades for Australian bank stocks
- **üìä Automatic Learning** - Builds ML models from your trading outcomes to improve over time  
- **üéØ Smart Signals** - Generates BUY/SELL/HOLD signals with confidence scores
- **üìà Performance Tracking** - Paper trading system tracks results and optimizes strategy

### **Supported Stocks**
- **CBA.AX** - Commonwealth Bank of Australia
- **WBC.AX** - Westpac Banking Corporation  
- **ANZ.AX** - Australia and New Zealand Banking Group
- **NAB.AX** - National Australia Bank

---

## üéØ **DAILY OPERATIONS** 

### **ÔøΩ COMMAND PRIORITY HIERARCHY**

#### **üåü TIER 1: ESSENTIAL DAILY COMMANDS (Must Run)**
These commands are **critical** for system operation and data collection:

**üåÖ Start Your Trading Day (30 seconds) - HIGHEST PRIORITY**
```bash
python daily_manager.py morning
```
**What it does:** 
- Starts `smart_collector.py` as a **background process** for continuous data collection
- Launches `news_trading_analyzer.py` web dashboard on localhost:8501
- Initializes ML pipeline and checks system health
- **Why critical:** Without this, no new training data is collected and no live signals are generated

**üîÑ How Smart Collector Works:**
- **Runs continuously** in background collecting data every 30 minutes
- **Automatically tracks signal outcomes** after 4-hour windows
- **Filters for high-quality signals** (confidence >75%, sentiment >0.3)
- **Keeps running until** you run `python daily_manager.py evening` or restart your computer

**üìä Quick Health Check (10 seconds) - HIGH PRIORITY**
```bash
python daily_manager.py status  
```
**What it does:**
- Shows ML model performance metrics (accuracy, sample count, class balance)
- Displays data collection rate and system uptime
- Identifies any critical issues requiring immediate attention
- **Why important:** Early detection of system problems prevents data loss

#### **üîß TIER 2: PERFORMANCE OPTIMIZATION (Run Weekly)**

**üìÖ Weekly Optimization (2 minutes) - MEDIUM-HIGH PRIORITY**
```bash
python daily_manager.py weekly
```
**What it does:**
- Retrains ML models on latest collected data using `MLTrainingPipeline`
- Performs feature engineering and model validation
- Generates comprehensive performance reports
- Cleans up old data and optimizes storage
- **Why essential:** ML models degrade without retraining; this keeps predictions accurate

**üåÜ End of Day Analysis (30 seconds) - MEDIUM PRIORITY**
```bash
python daily_manager.py evening
```
**What it does:**
- **Stops smart_collector.py background process** gracefully
- Generates daily performance summary reports
- Records trading outcomes and calculates win rates
- Saves system state for next trading day
- **Why useful:** Provides daily performance tracking and clean system shutdown

**üìù Important:** If you don't run the evening command, smart_collector will keep running until you restart your computer or manually stop it.

#### **üîç TIER 3: ANALYSIS & TROUBLESHOOTING (As Needed)**

**üìä Pattern Analysis (30 seconds) - LOW-MEDIUM PRIORITY**
```bash
python analyze_trading_patterns.py
```
**What it does:**
- Deep-dive analysis of trading performance patterns
- Identifies which stocks/timeframes perform best
- Generates correlation analysis between sentiment and actual returns
- **When to use:** Weekly or when investigating performance issues

**üö® Emergency Restart - TROUBLESHOOTING ONLY**
```bash
python daily_manager.py restart
```
**What it does:**
- Forcefully stops all background processes
- Clears any stuck data collection or analysis tasks
- Restarts the entire system from scratch
- **When to use:** Only when system is unresponsive or producing errors

### **üìã COMMAND EXECUTION FLOW**

#### **For New Users (First Week):**
1. **Morning:** `python daily_manager.py morning` (MUST RUN)
2. **Check:** `python daily_manager.py status` (Every few hours)
3. **Evening:** `python daily_manager.py evening` (Optional but recommended)
4. **Sunday:** `python daily_manager.py weekly` (CRITICAL for ML performance)

#### **For Experienced Users (Ongoing):**
1. **Daily:** Morning + Evening commands
2. **Weekly:** Weekly optimization + pattern analysis
3. **As Needed:** Status checks and troubleshooting

### **ÔøΩ CORE ARCHITECTURE EXPLAINED**

#### **Background Process Management**
- **`smart_collector.py`** - Runs continuously in background collecting high-quality training samples
- **`news_trading_analyzer.py`** - Main analysis engine that generates signals on-demand
- **`advanced_daily_collection.py`** - Orchestrates daily data collection workflows
- **`advanced_paper_trading.py`** - Simulates trades and tracks virtual portfolio performance

#### **Why These Components Are Separate:**
1. **Modularity** - Each component can be debugged/updated independently
2. **Scalability** - Background processes don't block user interface
3. **Reliability** - If one component fails, others continue operating
4. **Resource Management** - CPU-intensive ML training doesn't interfere with real-time analysis

### **ÔøΩüìà Dashboard Access**
After running morning routine, visit: **http://localhost:8501**

**New Features:**
- **üìä Historical Line Graphs** - View price, sentiment, momentum, and confidence trends over time
- **üîó Correlation Analysis** - See how sentiment correlates with actual price movements
- **üìà Multi-Bank Trend Comparison** - Compare sentiment trends across all banks
- **üéØ Top Movers** - Identify banks with the biggest sentiment/price changes

---

## üîß **SYSTEM SETUP**

### **Installation**
```bash
# Install dependencies
pip install -r requirements.txt

# Generate initial training data (optional)
python quick_sample_boost.py

# Start the system
python daily_manager.py morning
```

### **Core Scripts**
- **`daily_manager.py`** - Main control script (use this!)
- **`news_trading_analyzer.py`** - Core analysis engine
- **`launch_dashboard_auto.py`** - Web interface
- **`comprehensive_analyzer.py`** - System health checker
- **`analyze_trading_patterns.py`** - Performance pattern analysis and tracking

---

## üìä **UNDERSTANDING YOUR RESULTS**

### **Key Metrics to Monitor**

**üìà System Health Indicators**
- **Sample Count**: Target 100+ (you currently have 87 ‚úÖ)
- **Class Balance**: Target >0.3 (you have 0.64 ‚úÖ Excellent!)
- **Daily Collection**: Target 20+ (you have 127 ‚úÖ Outstanding!)
- **Win Rate**: Target >55% (tracks over time)

**üéØ Performance Targets**
- **Daily**: 5+ new samples, >95% uptime, >70% confidence
- **Weekly**: >60% model accuracy, positive returns, 25+ samples
- **Monthly**: Profit trend, 100+ new samples, system optimization

### **Reading the Dashboard**
- **Green signals** = BUY recommendations
- **Red signals** = SELL recommendations  
- **Yellow signals** = HOLD recommendations
- **Confidence scores** = How certain the ML model is (higher = better)

**üìä New Chart Features:**
- **Historical Trends** - Line graphs showing sentiment, confidence, price, and momentum over time
- **Correlation Plots** - Scatter plots showing sentiment vs. price movement relationships
- **Multi-Bank Comparison** - Compare trends across multiple banks simultaneously
- **Top Movers** - Identify banks with significant recent changes in sentiment or price

---

## ü§ñ **ML SYSTEM STATUS**

### **Current Capabilities**
‚úÖ **87 training samples** - Excellent progress
‚úÖ **ML models trained** - 60.6% accuracy (good for financial data)
‚úÖ **Automated collection** - 127 samples/day (outstanding rate)
‚úÖ **Real-time predictions** - Working with confidence scores
‚úÖ **Performance tracking** - Paper trading monitoring results

### **How the ML Works**
1. **Data Collection** - System monitors news sentiment for bank stocks
2. **Feature Engineering** - Extracts 10 key features from sentiment data
3. **Outcome Tracking** - Records whether trades are profitable  
4. **Model Training** - Uses your historical data to predict future trades
5. **Live Predictions** - Applies trained models to new sentiment data

---

## ‚ö†Ô∏è **TROUBLESHOOTING & DIAGNOSTICS**

### **üîß SYSTEMATIC PROBLEM RESOLUTION**

#### **Step 1: Quick Diagnostics**
```bash
# Check system health (30 seconds)
python daily_manager.py status
```
**Look for these red flags:**
- Sample count not increasing (data collection stopped)
- Model accuracy <50% (needs retraining)
- Collection rate 0/hour (background processes dead)
- Error messages in status output

#### **Step 2: Process Status Check**
```bash
# Check if background processes are running
ps aux | grep python | grep -E "(smart_collector|daily_manager)"

# Check system logs for errors
tail -20 logs/enhanced_trading_system.log
```

#### **Step 3: Escalating Fixes**

**üü° LEVEL 1: Soft Recovery (Try First)**
```bash
# Restart just the data collection
python daily_manager.py morning
```

**üü† LEVEL 2: Hard Reset (If Level 1 Fails)**
```bash
# Full system restart
python daily_manager.py restart
```

**üî¥ LEVEL 3: Manual Recovery (Last Resort)**
```bash
# Kill all Python processes manually
pkill -f "python.*daily_manager"
pkill -f "python.*smart_collector"

# Clear any stuck temporary files
rm -f data/ml_models/active_signals.json.tmp

# Restart from scratch
python daily_manager.py morning
```

### **üìä SPECIFIC ERROR SCENARIOS**

#### **"Dashboard not loading" (HTTP Error)**
**Symptoms:** Browser shows connection refused on localhost:8501
**Root Cause:** Streamlit process crashed or port blocked
**Solution:**
```bash
# Check if port is in use
lsof -i :8501

# Kill any stuck streamlit processes
pkill -f streamlit

# Restart dashboard
python daily_manager.py restart
```

#### **"No samples collecting" (Data Pipeline Failure)**
**Symptoms:** Sample count not increasing in status check
**Root Cause:** `smart_collector.py` process stopped or API failures
**Solution:**
```bash
# Check collector logs
tail -f logs/enhanced_trading_system.log | grep -i collector

# Manual sample boost
python quick_sample_boost.py

# Full restart
python daily_manager.py restart
```

#### **"Poor ML performance" (Model Degradation)**
**Symptoms:** Win rate <40%, confidence scores low, accuracy declining
**Root Cause:** Insufficient training data or stale models
**Solution:**
```bash
# Immediate retraining
python daily_manager.py weekly

# Check training data quality
python comprehensive_analyzer.py

# Generate more samples if needed
python quick_sample_boost.py
```

### **üö® ALERT CONDITIONS & RESPONSES**

#### **üî¥ CRITICAL ALERTS (Immediate Action Required)**
- **Model accuracy <60%** ‚Üí Run `python daily_manager.py weekly` immediately
- **No collection 2h+** ‚Üí Run `python daily_manager.py restart` 
- **Drawdown >5%** ‚Üí Review paper trading settings, run pattern analysis
- **System logs showing repeated errors** ‚Üí Check disk space, restart system

#### **üü° WARNING ALERTS (Address Within 24h)**
- **Low sample growth** ‚Üí Run `python quick_sample_boost.py`
- **Declining confidence** ‚Üí Monitor for another day, retrain if continues
- **High memory usage** ‚Üí Restart system during off-hours
- **Slow dashboard response** ‚Üí Clear browser cache, restart dashboard

### **üîç DEBUGGING COMMANDS FOR DEVELOPERS**

#### **Deep System Analysis**
```bash
# Comprehensive system health report
python comprehensive_analyzer.py

# ML pipeline detailed diagnostics  
python src/ml_training_pipeline.py --debug

# Background process monitoring
python core/smart_collector.py --once --verbose

# Manual signal generation test
python core/news_trading_analyzer.py --symbol CBA.AX --debug
```

#### **Log Analysis**
```bash
# View real-time system activity
tail -f logs/enhanced_trading_system.log

# Search for specific errors
grep -i "error\|exception\|failed" logs/enhanced_trading_system.log | tail -10

# Check data collection statistics
grep -i "collected\|sample" logs/enhanced_trading_system.log | tail -20
```

---

## üìÖ **RECOMMENDED SCHEDULE**

### **üöÄ NEW USER ONBOARDING (First 2 Weeks)**

#### **Day 1-3: System Initialization**
```bash
# Morning (9:00 AM) - CRITICAL
python daily_manager.py morning

# Midday check (12:00 PM) - Verify data collection
python daily_manager.py status

# Evening (5:00 PM) - Review first results
python daily_manager.py evening
```
**Goal:** Establish baseline data collection and verify system functionality

#### **Day 4-7: Data Accumulation**
```bash
# Morning routine only
python daily_manager.py morning

# Status checks every 2-3 hours
python daily_manager.py status
```
**Goal:** Build initial ML training dataset (target: 50+ samples)

#### **Week 2: First ML Training**
```bash
# Sunday - First model training (CRITICAL)
python daily_manager.py weekly

# Continue daily morning routine
python daily_manager.py morning
```
**Goal:** Train first ML models and begin predictive trading

### **üìã EXPERIENCED USER ROUTINE**

#### **Daily Routine (1 minute total)**
- **9:00 AM**: `python daily_manager.py morning` *(MANDATORY)*
- **5:00 PM**: `python daily_manager.py evening` *(Recommended)*

#### **Weekly Routine (2 minutes)**
- **Sunday 8:00 AM**: `python daily_manager.py weekly` *(CRITICAL for ML performance)*
- **Sunday 8:30 AM**: `python analyze_trading_patterns.py` *(Track improvements)*

#### **Monthly Routine (30 minutes)**
- Review performance reports in `reports/` folder
- Analyze long-term trends using pattern analysis
- Consider strategy adjustments based on win rates
- Archive old logs and clean up data storage

### **‚ö° AUTOMATION STRATEGIES**

#### **üñ•Ô∏è OPTION 1: Cloud/VPS Deployment (Recommended)**
Deploy your system on a cloud server that runs 24/7:

**Popular Options (Ranked by Suitability):**

**ü•á BEST: DigitalOcean Droplet** - $5/month basic plan
- **‚úÖ Perfect for this app:** 1GB RAM, 25GB SSD, unlimited bandwidth
- **‚úÖ Simple setup:** No complex billing, straightforward interface
- **‚úÖ Reliable:** 99.99% uptime SLA, excellent for 24/7 trading
- **‚úÖ Easy scaling:** One-click resize if you need more resources
- **‚ö° Quick start:** 5 minutes from signup to running system

**ü•à GOOD: Linode** - $5/month Nanode plan  
- **‚úÖ Similar specs:** 1GB RAM, 25GB SSD
- **‚úÖ Developer-friendly:** Clean interface, good documentation
- **‚úÖ Competitive pricing:** Same cost as DigitalOcean
- **‚ö†Ô∏è Slightly more complex:** Setup process has more steps

**ü•â FREE BUT LIMITED: AWS EC2** - t2.micro (free tier)
- **‚úÖ Free for 12 months:** 1GB RAM, 30GB storage
- **‚ùå Complex billing:** Easy to accidentally exceed free tier
- **‚ùå Complicated setup:** VPC, security groups, key pairs
- **‚ùå Performance limits:** CPU bursting can throttle your app
- **‚ö†Ô∏è After 12 months:** Costs more than DigitalOcean

**ü•â FREE BUT LIMITED: Google Cloud Compute** - e2-micro (free tier)
- **‚úÖ Always free:** 0.25GB RAM (too small for your app)
- **‚ùå Insufficient RAM:** Your ML models need more memory
- **‚ùå Complex interface:** Steeper learning curve
- **‚ùå Billing complexity:** Easy to trigger charges accidentally

**Setup Steps:**
```bash
# 1. Create cloud instance with Ubuntu 20.04+
# 2. Install Python and dependencies
sudo apt update && sudo apt install python3 python3-pip git
git clone [your-repo-url]
cd trading_analysis
pip3 install -r requirements.txt

# 3. Setup cron jobs on cloud server
crontab -e
# Add the cron jobs below
```

#### **üè† OPTION 2: Always-On Local Device**
Use a Raspberry Pi, old laptop, or Mac Mini as a dedicated trading server:

**Raspberry Pi 4 Setup ($75 solution):**
```bash
# Install Raspberry Pi OS Lite
# SSH into Pi and setup Python environment
ssh pi@your-pi-ip
sudo apt update && sudo apt install python3-pip git
# Clone repo and install dependencies
```

#### **üíª OPTION 3: Laptop with Wake-on-Schedule**
Configure your Mac to wake up automatically for trading hours:

**macOS Power Management:**
```bash
# Set laptop to wake at 8:45 AM weekdays (before market open)
sudo pmset repeat wakeorpoweron MTWRF 08:45:00

# Set laptop to sleep at 6:00 PM weekdays (after market close)  
sudo pmset repeat sleep MTWRF 18:00:00

# Prevent sleep during market hours
sudo pmset -c sleep 0 displaysleep 10 disksleep 0
```

#### **üîÑ OPTION 4: Manual but Optimized**
Streamlined manual process for when you're working from home:

**Morning Routine (2 minutes):**
```bash
# Create this alias in ~/.zshrc for super quick startup
alias trading-start="cd /Users/toddsutherland/Repos/trading_analysis && python daily_manager.py morning && open http://localhost:8501"

# Just run: trading-start
```

**Evening Routine (30 seconds):**
```bash
# Create alias for quick shutdown
alias trading-stop="cd /Users/toddsutherland/Repos/trading_analysis && python daily_manager.py evening"

# Just run: trading-stop
```

#### **ü§ñ FULL AUTOMATION CRON JOBS (For 24/7 Systems)**
```bash
# Edit crontab (crontab -e) to add these lines:

# Monday-Friday: Start system at 9:00 AM AEST (market open)
0 9 * * 1-5 cd /path/to/trading_analysis && /usr/bin/python3 daily_manager.py morning

# Monday-Friday: End of day analysis at 5:00 PM AEST (market close)  
0 17 * * 1-5 cd /path/to/trading_analysis && /usr/bin/python3 daily_manager.py evening

# Sunday: Weekly ML retraining at 8:00 AM
0 8 * * 0 cd /path/to/trading_analysis && /usr/bin/python3 daily_manager.py weekly

# Health check every 2 hours during market days
0 */2 * * 1-5 cd /path/to/trading_analysis && /usr/bin/python3 daily_manager.py status >> logs/cron_status.log

# Emergency restart if system becomes unresponsive (runs every 4 hours)
0 */4 * * 1-5 cd /path/to/trading_analysis && pgrep -f "smart_collector" > /dev/null || /usr/bin/python3 daily_manager.py restart
```

#### **üì± MOBILE MONITORING (For Any Setup)**
Get notified about your trading system via email/SMS:

**Email Alerts Setup:**
```bash
# Add to your cron jobs for critical alerts
# Install mail command: brew install mailutils (macOS) or apt install mailutils (Linux)

# Daily status email
0 18 * * 1-5 cd /path/to/trading_analysis && python daily_manager.py status | mail -s "Trading System Status $(date)" your-email@gmail.com

# Error alert (runs every hour, only emails if errors found)
0 * * * 1-5 cd /path/to/trading_analysis && grep -i "error\|exception" logs/enhanced_trading_system.log | tail -5 | mail -s "TRADING SYSTEM ERROR" your-email@gmail.com 2>/dev/null || true
```

### **üéØ RECOMMENDATION: DigitalOcean Droplet**

**Why DigitalOcean is perfect for your trading system:**

#### **Technical Suitability:**
- **1GB RAM** - Sufficient for ML models, sentiment analysis, and background processes
- **25GB SSD** - Fast storage for historical data and model files
- **1TB bandwidth** - More than enough for news feeds and price data
- **Ubuntu 22.04** - Perfect match for your Python application

#### **Ease of Use:**
- **5-minute setup** - Create droplet ‚Üí SSH ‚Üí Install dependencies ‚Üí Done
- **Predictable billing** - Flat $5/month, no surprise charges
- **Simple interface** - No complex AWS-style configurations
- **One-click backups** - Easy data protection for $1/month extra

#### **Application-Specific Benefits:**
- **24/7 reliability** - Your smart_collector can run continuously
- **Remote dashboard access** - View at `http://your-server-ip:8501` from anywhere
- **Easy scaling** - Resize to 2GB RAM ($12/month) if needed later
- **SSH access** - Full control for debugging and maintenance

#### **Cost Analysis:**
```
DigitalOcean:     $5/month  = $60/year
Laptop 24/7:      ~$180/year (electricity + wear)
AWS after free:   ~$8-15/month (variable pricing)
```






**Winner: DigitalOcean saves money AND provides better reliability**

#### **Quick Start Command:**
```bash
# After creating your droplet, just run:
ssh root@your-droplet-ip
curl -fsSL https://raw.githubusercontent.com/yourusername/trading_analysis/main/deploy.sh | bash
```

**Bottom Line:** DigitalOcean is the sweet spot of simplicity, reliability, and cost for your ML trading system.

---

## üåä **DIGITALOCEAN DEPLOYMENT GUIDE**

*Complete step-by-step guide for deploying your ML trading system to DigitalOcean*

---

### **üöÄ PART 1: DROPLET CREATION & INITIAL SETUP**

#### **Step 1: Create DigitalOcean Account & Droplet (5 minutes)**

**1.1 Sign Up & Get Credits:**
```bash
# Visit: https://digitalocean.com
# Use referral link for $200 free credits (2 months free)
# Or search for "DigitalOcean promo codes" for current offers
```

**1.2 Create Your Droplet:**
1. **Click "Create" ‚Üí "Droplets"**
2. **Choose Image:** Ubuntu 22.04 (LTS) x64
3. **Choose Plan:** Basic ‚Üí Regular ‚Üí $5/month (1GB RAM, 25GB SSD)
4. **Choose Region:** Sydney (closest to ASX for faster data feeds)
5. **Authentication:** SSH Key (recommended) or Password
6. **Hostname:** `trading-server` or similar
7. **Click "Create Droplet"**

**1.3 Note Your Server Details:**
```bash
# Save these details securely:
Server IP: xxx.xxx.xxx.xxx
Root Password: (if using password auth)
SSH Key: (if using key auth)
```

#### **Step 2: Initial Server Configuration (10 minutes)**

**2.1 Connect to Your Server:**

**Option A: Using SSH Key (Recommended):**
```bash
# Connect directly using your server's IP address
ssh root@your-server-ip

# Example with your actual IP:
ssh root@170.64.199.151
```

**Option B: Using SSH Key with Specific Key File:**
```bash
# If your SSH key is in a specific location
ssh -i ~/.ssh/id_rsa root@your-server-ip
ssh -i ~/.ssh/sshanalysis root@your-server-ip

# Example with your specific setup:
ssh -i ~/.ssh/sshanalysis root@170.64.199.151
```

**Option C: Using Password (Less Secure):**
```bash
# Connect with password authentication
ssh root@your-server-ip
# Enter password when prompted
```

**Troubleshooting SSH Connection:**
```bash
# Test SSH connection with verbose output
ssh -v root@your-server-ip

# Check if your SSH key is loaded
ssh-add -l

# Add your SSH key if not loaded
ssh-add ~/.ssh/id_rsa
ssh-add ~/.ssh/sshanalysis
```

**2.2 Update System & Install Dependencies:**
```bash
# Update package list and system
apt update && apt upgrade -y

# When prompted about SSH config file, choose option 2:
# "keep the local version currently installed"
# This preserves your SSH key authentication settings

# Install Python 3, pip, git, and other essentials
apt install -y python3 python3-pip git htop nano ufw curl wget

# Install system monitoring tools
apt install -y fail2ban logwatch

# Verify Python installation
python3 --version  # Should show Python 3.10+
pip3 --version     # Should show pip version
```

**2.3 Configure Firewall & Security:**
```bash
# Setup UFW firewall
ufw default deny incoming
ufw default allow outgoing
ufw allow ssh
ufw allow 8501  # For Streamlit dashboard
ufw --force enable

# Configure fail2ban for SSH protection
systemctl enable fail2ban
systemctl start fail2ban

# Check firewall status
ufw status verbose
```

#### **Step 3: Deploy Your Trading System (15 minutes)**

**3.1 Clone Your Repository:**
```bash
# Navigate to home directory
cd /root

# Clone your repository (replace with your actual repo URL)
git clone https://github.com/yourusername/trading_analysis.git
cd trading_analysis

# Verify files are present
ls -la
```

**3.2 Install Python Dependencies:**
```bash
# Install all required packages
pip3 install -r requirements.txt

# If you get permission errors, try:
pip3 install --user -r requirements.txt

# Verify key packages are installed
python3 -c "import streamlit, pandas, numpy, sklearn; print('‚úÖ All packages installed')"
```

**3.3 Initial System Test:**
```bash
# Test the system startup
python3 daily_manager.py morning

# Wait 30 seconds, then check status
python3 daily_manager.py status

# If everything works, stop for now
python3 daily_manager.py evening
```

**3.4 Configure System Paths:**
```bash
# Create systemd service for auto-startup
nano /etc/systemd/system/trading-system.service
```

**Add this content to the service file:**
```ini
[Unit]
Description=ML Trading System
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/root/trading_analysis
ExecStart=/usr/bin/python3 daily_manager.py morning
ExecStop=/usr/bin/python3 daily_manager.py evening
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Enable the service:**
```bash
# Reload systemd and enable service
systemctl daemon-reload
systemctl enable trading-system
systemctl start trading-system

# Check service status
systemctl status trading-system
```

---

### **üîÑ PART 2: AUTOMATED BACKUP SYSTEM**

#### **Step 1: Set Up Local Backup Scripts**

**1.1 Create Backup Directory on Your Mac:**
```bash
# On your local Mac, create backup directory
mkdir -p ~/trading-backups/daily
mkdir -p ~/trading-backups/weekly
mkdir -p ~/trading-backups/models
```

**1.2 Create Backup Script on Mac:**
```bash
# Create backup script
nano ~/trading-backups/backup-trading-data.sh
```

**Add this content:**
```bash
#!/bin/bash

# Configuration
SERVER_IP="your-server-ip-here"
SERVER_USER="root"
BACKUP_DIR="$HOME/trading-backups"
DATE=$(date +%Y%m%d_%H%M%S)

echo "üîÑ Starting backup at $(date)"

# Create timestamped backup directory
mkdir -p "$BACKUP_DIR/daily/$DATE"

# Backup critical data directories
echo "üìÅ Backing up data directory..."
rsync -avz --compress-level=9 $SERVER_USER@$SERVER_IP:/root/trading_analysis/data/ "$BACKUP_DIR/daily/$DATE/data/"

echo "üìä Backing up reports..."
rsync -avz --compress-level=9 $SERVER_USER@$SERVER_IP:/root/trading_analysis/reports/ "$BACKUP_DIR/daily/$DATE/reports/"

echo "üìú Backing up logs..."
rsync -avz --compress-level=9 $SERVER_USER@$SERVER_IP:/root/trading_analysis/logs/ "$BACKUP_DIR/daily/$DATE/logs/"

echo "‚öôÔ∏è Backing up config..."
rsync -avz --compress-level=9 $SERVER_USER@$SERVER_IP:/root/trading_analysis/config/ "$BACKUP_DIR/daily/$DATE/config/"

# Backup ML models specifically
echo "üß† Backing up ML models..."
rsync -avz --compress-level=9 $SERVER_USER@$SERVER_IP:/root/trading_analysis/data/ml_models/ "$BACKUP_DIR/models/$DATE/"

# Create compressed archive
echo "üóúÔ∏è Creating compressed backup..."
cd "$BACKUP_DIR/daily"
tar -czf "trading_backup_$DATE.tar.gz" "$DATE"
rm -rf "$DATE"

# Clean up old backups (keep last 30 days)
find "$BACKUP_DIR/daily" -name "*.tar.gz" -mtime +30 -delete
find "$BACKUP_DIR/models" -mtime +7 -delete

echo "‚úÖ Backup completed: trading_backup_$DATE.tar.gz"
echo "üìä Backup size: $(du -h "$BACKUP_DIR/daily/trading_backup_$DATE.tar.gz" | cut -f1)"
```

**Make script executable:**
```bash
chmod +x ~/trading-backups/backup-trading-data.sh
```

**1.3 Test Backup Script:**
```bash
# Edit script to add your server IP
nano ~/trading-backups/backup-trading-data.sh
# Replace "your-server-ip-here" with actual IP

# Test the backup
~/trading-backups/backup-trading-data.sh
```

#### **Step 2: Automated Backup Scheduling**

**2.1 Set Up Local Cron Jobs:**
```bash
# Edit your local crontab
crontab -e

# Add these lines for automated backups:
# Daily backup at 6 PM
0 18 * * * /Users/$(whoami)/trading-backups/backup-trading-data.sh >> /Users/$(whoami)/trading-backups/backup.log 2>&1

# Weekly full system backup (Sundays at 7 PM)
0 19 * * 0 rsync -avz root@your-server-ip:/root/trading_analysis/ /Users/$(whoami)/trading-backups/weekly/full_backup_$(date +\%Y\%m\%d)/ >> /Users/$(whoami)/trading-backups/backup.log 2>&1
```

**2.2 Create Backup Monitoring Script:**
```bash
# Create monitoring script
nano ~/trading-backups/check-backups.sh
```

**Add this content:**
```bash
#!/bin/bash

BACKUP_DIR="$HOME/trading-backups"
LATEST_BACKUP=$(ls -t "$BACKUP_DIR/daily"/*.tar.gz 2>/dev/null | head -1)

if [ -z "$LATEST_BACKUP" ]; then
    echo "‚ùå No backups found!"
    exit 1
fi

BACKUP_AGE=$(stat -f %m "$LATEST_BACKUP")
CURRENT_TIME=$(date +%s)
AGE_HOURS=$(( (CURRENT_TIME - BACKUP_AGE) / 3600 ))

echo "üìä Backup Status Report"
echo "Latest backup: $(basename "$LATEST_BACKUP")"
echo "Backup age: $AGE_HOURS hours"
echo "Backup size: $(du -h "$LATEST_BACKUP" | cut -f1)"

if [ $AGE_HOURS -gt 36 ]; then
    echo "‚ö†Ô∏è WARNING: Backup is older than 36 hours!"
else
    echo "‚úÖ Backup is recent"
fi

# Show disk usage
echo "üíæ Backup directory usage: $(du -sh "$BACKUP_DIR" | cut -f1)"
```

**Make executable and test:**
```bash
chmod +x ~/trading-backups/check-backups.sh
~/trading-backups/check-backups.sh
```

---

### **üõ†Ô∏è PART 3: SERVER MONITORING & MAINTENANCE**

#### **Step 1: System Monitoring Setup**

**1.1 Create Server Health Check Script:**
```bash
# On your DigitalOcean server, create monitoring script
nano /root/trading_analysis/server-health.sh
```

**Add this content:**
```bash
#!/bin/bash

echo "üñ•Ô∏è Server Health Report - $(date)"
echo "=================================="

# System resources
echo "üíæ Memory Usage:"
free -h | grep -E "Mem|Swap"

echo -e "\nüíø Disk Usage:"
df -h | grep -E "/$|/root"

echo -e "\nüî• CPU Load:"
uptime

echo -e "\nüêç Python Processes:"
ps aux | grep python3 | grep -v grep | wc -l
echo "Active Python processes: $(ps aux | grep python3 | grep -v grep | wc -l)"

echo -e "\nüìä Trading System Status:"
cd /root/trading_analysis
python3 daily_manager.py status

echo -e "\nüåê Network Connectivity:"
ping -c 3 8.8.8.8 > /dev/null && echo "‚úÖ Internet OK" || echo "‚ùå Internet DOWN"

echo -e "\nüìú Recent Errors:"
tail -20 logs/enhanced_trading_system.log | grep -i error | tail -5

echo "=================================="
```

**Make executable:**
```bash
chmod +x /root/trading_analysis/server-health.sh
```

**1.2 Set Up Email Alerts (Optional but Recommended):**
```bash
# Install mail utilities
apt install -y mailutils postfix

# Configure postfix (choose "Internet Site" and enter your domain)
# Or use external SMTP service

# Test email (replace with your email)
echo "Test from trading server" | mail -s "Trading Server Test" your-email@gmail.com
```

#### **Step 2: Automated Server Maintenance**

**2.1 Create Maintenance Script:**
```bash
nano /root/trading_analysis/maintenance.sh
```

**Add this content:**
```bash
#!/bin/bash

echo "üîß Starting server maintenance - $(date)"

# Update system packages
apt update && apt upgrade -y

# Clean up logs older than 30 days
find /root/trading_analysis/logs -name "*.log" -mtime +30 -delete

# Clean up old report files (keep last 50)
cd /root/trading_analysis/reports
ls -t *.html 2>/dev/null | tail -n +51 | xargs rm -f

# Restart trading system to clear memory
systemctl restart trading-system

# Check system status
sleep 30
python3 /root/trading_analysis/daily_manager.py status

echo "‚úÖ Maintenance completed - $(date)"
```

**Make executable and schedule:**
```bash
chmod +x /root/trading_analysis/maintenance.sh

# Add to server crontab for weekly maintenance
crontab -e

# Add this line for Sunday 2 AM maintenance
0 2 * * 0 /root/trading_analysis/maintenance.sh >> /root/trading_analysis/logs/maintenance.log 2>&1
```

---

### **üîë PART 4: ACCESS & SECURITY MANAGEMENT**

#### **Step 1: SSH Key Management**

**1.1 Generate SSH Key Pair (if not done already):**
```bash
# On your local Mac, generate SSH key
ssh-keygen -t rsa -b 4096 -C "trading-server-key"

# Copy public key to server
ssh-copy-id root@your-server-ip
```

**1.2 Secure SSH Configuration:**
```bash
# On server, edit SSH config
nano /etc/ssh/sshd_config

# Add/modify these lines:
PermitRootLogin yes
PasswordAuthentication no
PubkeyAuthentication yes
Port 22

# Restart SSH service
systemctl restart sshd
```

#### **Step 2: Dashboard Access Setup**

**2.1 Access Your Dashboard Remotely:**
```bash
# Your dashboard will be available at:
http://your-server-ip:8501

# Example with your IP:
http://170.64.199.151:8501

# Create bookmark for easy access
```

**2.2 Optional: Dynamic DNS (Alternative to Domain):**
```bash
# If your IP changes frequently, consider free dynamic DNS services:
# - No-IP (noip.com) - Free hostnames like yourname.ddns.net
# - DuckDNS (duckdns.org) - Free subdomains like yourname.duckdns.org
# - Dynu (dynu.com) - Free DNS with API support

# Most cloud servers have static IPs, so this is usually not needed
```

---

### **üìã PART 5: DAILY OPERATIONS CHECKLIST**

#### **Daily Tasks (2 minutes):**
```bash
# Check backup status
~/trading-backups/check-backups.sh

# Quick server health check (via SSH)
ssh root@your-server-ip '/root/trading_analysis/server-health.sh'

# View dashboard (replace with your actual IP)
open http://170.64.199.151:8501
```

#### **Weekly Tasks (5 minutes):**
```bash
# Full system backup verification
ls -la ~/trading-backups/weekly/

# Server maintenance check
ssh root@your-server-ip 'systemctl status trading-system'

# Review system logs
ssh root@your-server-ip 'tail -50 /root/trading_analysis/logs/enhanced_trading_system.log'
```

#### **Monthly Tasks (15 minutes):**
```bash
# Update system packages
ssh root@your-server-ip 'apt update && apt upgrade -y'

# Review backup storage usage
du -sh ~/trading-backups/

# Clean old backups if needed
find ~/trading-backups/daily -name "*.tar.gz" -mtime +60 -delete

# Performance review via dashboard
```

---

### **üö® PART 6: EMERGENCY PROCEDURES**

#### **Scenario 1: Server Becomes Unresponsive**
```bash
# 1. Try SSH connection
ssh root@your-server-ip

# 2. If SSH fails, use DigitalOcean console
# Go to DigitalOcean dashboard ‚Üí Your droplet ‚Üí Console

# 3. If console accessible, restart services
systemctl restart trading-system

# 4. If nothing works, reboot droplet
# DigitalOcean dashboard ‚Üí Power cycle
```

#### **Scenario 2: Data Corruption/Loss**
```bash
# 1. Stop trading system
ssh root@your-server-ip 'systemctl stop trading-system'

# 2. Restore from latest backup
cd ~/trading-backups/daily
LATEST=$(ls -t *.tar.gz | head -1)
scp "$LATEST" root@your-server-ip:/tmp/

# 3. On server, extract backup
ssh root@your-server-ip
cd /tmp
tar -xzf trading_backup_*.tar.gz
cp -r */data /root/trading_analysis/
cp -r */config /root/trading_analysis/

# 4. Restart system
systemctl start trading-system
```

#### **Scenario 3: Complete Server Rebuild**
```bash
# 1. Create new droplet (same specs)
# 2. Follow deployment guide from Step 1
# 3. Restore data from backups
# 4. Update DNS/bookmarks with new IP
```

---

### **üí° PART 7: OPTIMIZATION TIPS**

#### **Performance Tuning:**
```bash
# Monitor resource usage
ssh root@your-server-ip 'htop'

# If memory usage is high, consider upgrading to 2GB plan ($12/month)
# DigitalOcean dashboard ‚Üí Resize droplet

# Optimize Python memory usage
echo 'export PYTHONOPTIMIZE=1' >> ~/.bashrc
```

#### **Cost Optimization:**
```bash
# Monitor bandwidth in DO dashboard
# 1TB included should be more than enough
# Consider enabling monitoring alerts for 80% usage

# Use compression for large backups
# Already implemented in backup scripts
```

#### **Security Hardening:**
```bash
# Regular security updates
ssh root@your-server-ip 'apt update && apt upgrade -y'

# Monitor failed login attempts
ssh root@your-server-ip 'grep "Failed password" /var/log/auth.log | tail -20'

# Consider changing SSH port if seeing many attack attempts
```

---

### **üìû SUPPORT & TROUBLESHOOTING**

#### **Common Issues & Solutions:**

**Issue: "Cannot connect to server"**
- Check server is running in DigitalOcean dashboard
- Verify IP address hasn't changed
- Check local internet connection

**Issue: "Dashboard not loading"**
- SSH to server: `ssh root@your-server-ip`
- Check service: `systemctl status trading-system`
- Restart if needed: `systemctl restart trading-system`

**Issue: "Backup failing"**
- Check SSH key authentication
- Verify disk space: `df -h`
- Check backup script permissions

**Issue: "High server costs"**
- Monitor bandwidth in DO dashboard
- Basic $5 plan should be sufficient
- Contact DigitalOcean support for billing questions

#### **Getting Help:**
- **DigitalOcean Support:** Available 24/7 via ticket system
- **Community Forums:** digitalocean.com/community
- **Documentation:** docs.digitalocean.com

---

### **üéâ DEPLOYMENT COMPLETE!**

**Your ML trading system is now running 24/7 on DigitalOcean with:**
- ‚úÖ Automated data collection every 30 minutes
- ‚úÖ Daily backups to your local Mac
- ‚úÖ Remote dashboard access from anywhere via IP address
- ‚úÖ Automated maintenance and monitoring
- ‚úÖ Emergency recovery procedures

**Access your system:**
- **Dashboard:** `http://170.64.199.151:8501` (replace with your actual IP)
- **SSH Access:** `ssh root@170.64.199.151` (replace with your actual IP)
- **Local Backups:** `~/trading-backups/`

**Monthly cost: $5 (much less than leaving your laptop on 24/7!)**

Your trading system will now run continuously, collecting data and improving its ML models without any intervention from you. Check the dashboard daily and let the system learn!

### **üîë SSH CONNECTION QUICK REFERENCE**

#### **Most Common Connection Methods:**

**Connect using your server's IP address:**
```bash
# Connect using IP (most common method)
ssh root@170.64.199.151

# Or if you have a different IP:
ssh root@159.203.123.45
```

**If your SSH key isn't in the default location:**
```bash
# Specify key file location
ssh -i /path/to/your/key root@your-server-ip
ssh -i ~/.ssh/sshanalysis root@170.64.199.151

# Example with your specific key:
ssh -i ~/.ssh/sshanalysis root@170.64.199.151
```

#### **First-Time Connection Setup:**

**1. Find Your Connection Details:**
```bash
# From DigitalOcean dashboard, note:
# - Server IP: xxx.xxx.xxx.xxx
# - Hostname: your-chosen-hostname
# - SSH Key: Should be automatically configured
```

**2. Test Your Connection:**
```bash
# Try connecting (replace with your actual IP)
ssh root@170.64.199.151

# If it asks "Are you sure you want to continue connecting?", type: yes
# You should see a prompt like: root@trading-server:~#
```

**3. Common First-Time Issues:**

**Issue: "Permission denied (publickey)"**
```bash
# Solution: Add your SSH key to the agent
ssh-add ~/.ssh/id_rsa
ssh-add ~/.ssh/sshanalysis

# Or specify your key directly
ssh -i ~/.ssh/sshanalysis root@170.64.199.151
```

**Issue: "Host key verification failed"**
```bash
# Solution: Remove old host key and try again
ssh-keygen -R your-server-ip
ssh-keygen -R 170.64.199.151
ssh root@170.64.199.151
```

**Issue: "Connection timed out"**
```bash
# Solution: Check server is running in DigitalOcean dashboard
# Verify firewall allows SSH (port 22)
```

#### **Quick Connection Test:**
```bash
# Once connected, verify everything works:
whoami          # Should show: root
hostname        # Should show your server hostname
pwd             # Should show: /root
ls              # Should show your files
```

---

#### **üö® COMMON SSH CONNECTION ISSUES**

**Issue: "Could not resolve hostname ubuntu-s-1vcpu-1gb-syd1-01"**
```bash
# ERROR: ssh ubuntu-s-1vcpu-1gb-syd1-01
# ssh: Could not resolve hostname ubuntu-s-1vcpu-1gb-syd1-01: nodename nor servname provided, or not known
```

**‚ùå Problem:** `ubuntu-s-1vcpu-1gb-syd1-01` is DigitalOcean's internal droplet name, not a public hostname.

**‚úÖ Solution:** Use the actual IP address instead:
```bash
# 1. Get your droplet's IP address from DigitalOcean dashboard
# Go to: DigitalOcean ‚Üí Droplets ‚Üí Your droplet ‚Üí Copy the IP address

# 2. Connect using the IP address
ssh root@your-actual-ip-address

# Example with your IP:
ssh root@170.64.199.151

# Other examples:
ssh root@159.203.123.45
ssh root@167.99.234.56
```

**üìã How to Find Your IP Address:**
1. **Login to DigitalOcean dashboard:** https://cloud.digitalocean.com
2. **Click "Droplets"** in the left sidebar
3. **Find your droplet** (ubuntu-s-1vcpu-1gb-syd1-01)
4. **Copy the IP address** shown next to your droplet name
5. **Use that IP** for SSH connection

**üí° Pro Tip:** Save your connection details for easy access:
```bash
# Create an alias in your ~/.zshrc or ~/.bash_profile
echo 'alias trading-ssh="ssh -i ~/.ssh/sshanalysis root@170.64.199.151"' >> ~/.zshrc
source ~/.zshrc

# Then just use:
trading-ssh
```

---
